{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files in the Details folder\n",
    "details_path = \"../Data/Details/\"\n",
    "files = [f\"{details_path}{filename}\" for filename in os.listdir(details_path) if os.path.isfile((os.path.join(details_path, filename)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_OTHER_STATE_FIPS</th>\n",
       "      <th>TOR_OTHER_CZ_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TOR_OTHER_STATE_FIPS TOR_OTHER_CZ_STATE\n",
       "0                   01                 AL\n",
       "1                   02                 AK\n",
       "2                   04                 AZ\n",
       "3                   05                 AR\n",
       "4                   06                 CA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get state FIPS for OTHER_FIPS conversion\n",
    "state_fips_path = \"../Data/cleaned_state.csv\"\n",
    "state_fips_df = pd.read_csv(state_fips_path, dtype=str)\n",
    "state_fips_df = state_fips_df.rename(columns={\"STATEFP\": \"TOR_OTHER_STATE_FIPS\", \"STATE\": \"TOR_OTHER_CZ_STATE\"})\n",
    "state_fips_df = state_fips_df.drop(columns=[\"Unnamed: 0\"])\n",
    "state_fips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../Data/Cleaned/\"\n",
    "tornado_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>CZ_TIMEZONE_RECODE</th>\n",
       "      <th>UTC_OFFSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CST</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MST</td>\n",
       "      <td>MST-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EST</td>\n",
       "      <td>EST-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PST</td>\n",
       "      <td>PST-8</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CDT</td>\n",
       "      <td>CDT-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDT</td>\n",
       "      <td>EDT-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MDT</td>\n",
       "      <td>MDT-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GMT</td>\n",
       "      <td>GMT-0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HST</td>\n",
       "      <td>HST-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PDT</td>\n",
       "      <td>PDT-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CSC</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AST</td>\n",
       "      <td>AST-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EST-5</td>\n",
       "      <td>EST-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MST-7</td>\n",
       "      <td>MST-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CST-6</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PST-8</td>\n",
       "      <td>PST-8</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AST-4</td>\n",
       "      <td>AST-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HST-10</td>\n",
       "      <td>HST-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AKST-9</td>\n",
       "      <td>AKST-9</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CZ_TIMEZONE CZ_TIMEZONE_RECODE  UTC_OFFSET\n",
       "0          CST              CST-6          -6\n",
       "1          MST              MST-7          -7\n",
       "2          EST              EST-5          -5\n",
       "3          PST              PST-8          -8\n",
       "4          UNK                UNK           0\n",
       "5          CDT              CDT-5          -5\n",
       "6          EDT              EDT-4          -4\n",
       "7          MDT              MDT-6          -6\n",
       "8          GMT              GMT-0           0\n",
       "9          HST             HST-10         -10\n",
       "10         PDT              PDT-7          -7\n",
       "11         CSC              CST-6          -6\n",
       "12         AST              AST-4          -4\n",
       "13       EST-5              EST-5          -5\n",
       "14       MST-7              MST-7          -7\n",
       "15       CST-6              CST-6          -6\n",
       "16       PST-8              PST-8          -8\n",
       "17       AST-4              AST-4          -4\n",
       "18      HST-10             HST-10         -10\n",
       "19      AKST-9             AKST-9          -9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timezone data\n",
    "tz_codes = ['CST', 'MST', 'EST', 'PST', 'UNK', 'CDT', 'EDT', 'MDT', 'GMT', 'HST', 'PDT', 'CSC',\n",
    " 'AST', 'EST-5', 'MST-7', 'CST-6', 'PST-8', 'AST-4', 'HST-10', 'AKST-9']\n",
    "tz_offsets = [-6, -7, -5, -8, 0, -5, -4, -6, 0, -10, -7, -6, -4, -5, -7, -6, -8, -4, -10, -9]\n",
    "tz_recode = ['CST-6', 'MST-7', 'EST-5', 'PST-8', 'UNK', 'CDT-5', 'EDT-4', 'MDT-6', 'GMT-0',\n",
    "             'HST-10', 'PDT-7', 'CST-6', 'AST-4', 'EST-5', 'MST-7', 'CST-6', 'PST-8', 'AST-4',\n",
    "             'HST-10', 'AKST-9']\n",
    "timezones_df = pd.DataFrame({\n",
    "    \"CZ_TIMEZONE\": tz_codes,\n",
    "    \"CZ_TIMEZONE_RECODE\": tz_recode,\n",
    "    \"UTC_OFFSET\": tz_offsets\n",
    "})\n",
    "\n",
    "timezones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    print(f\"Processing file {file}\")\n",
    "    # Read file. Set FIPS columns to string\n",
    "    detail_data_raw_df = pd.read_csv(file, dtype={\"STATE_FIPS\": str,\n",
    "                                                  \"CZ_FIPS\": str,\n",
    "                                                  \"TOR_OTHER_CZ_FIPS\": str,\n",
    "                                                  \"DAMAGE_PROPERTY\": str,\n",
    "                                                  \"DAMAGE_CROPS\": str,\n",
    "                                                  \"BEGIN_AZIMUTH\": str,\n",
    "                                                  \"BEGIN_LOCATION\": str,\n",
    "                                                  \"END_AZIMUTH\": str,\n",
    "                                                  \"END_LOCATION\": str})\n",
    "    \n",
    "    # Filter tornadoes\n",
    "    detail_data_clean_df = detail_data_raw_df[detail_data_raw_df[\"EVENT_TYPE\"] == \"Tornado\"]\n",
    "    \n",
    "    # Renumber Puerto Rico & Virgin Islands state FIPS\n",
    "    detail_data_clean_df.loc[detail_data_clean_df[\"STATE\"] == \"PUERTO RICO\", \"STATE_FIPS\"] = \"72\"\n",
    "    detail_data_clean_df.loc[detail_data_clean_df[\"STATE\"] == \"VIRGIN ISLANDS\", \"STATE_FIPS\"] = \"78\"\n",
    "\n",
    "    # Combine State and County FIPS\n",
    "    detail_data_clean_df[\"FIPS\"] = (detail_data_clean_df[\"STATE_FIPS\"].str.zfill(2)) + (detail_data_clean_df[\"CZ_FIPS\"].str.zfill(3))\n",
    "    \n",
    "    # Process timestamps\n",
    "    pattern = r'-\\d{2}'\n",
    "    detail_data_clean_df[\"YEAR\"] = detail_data_clean_df[\"YEAR\"].astype(str)\n",
    " \n",
    "    # FROM MICROSOFT COPILOT\n",
    "    # Replace 2-digit year with 4-digit year for timestamp creation\n",
    "    detail_data_clean_df[\"BEGIN_DATE_TIME\"] = detail_data_clean_df.apply(\n",
    "        lambda row: pd.Series(row[\"BEGIN_DATE_TIME\"]).str.replace(pattern, f\"-{row[\"YEAR\"]}\", regex=True)[0],axis=1)\n",
    "    detail_data_clean_df[\"END_DATE_TIME\"] = detail_data_clean_df.apply(\n",
    "        lambda row: pd.Series(row[\"END_DATE_TIME\"]).str.replace(pattern, f\"-{row[\"YEAR\"]}\", regex=True)[0],axis=1)\n",
    "    \n",
    "    # Convert BEGIN_DATE_TIME and END_DATE_TIME to UTC UNIX (POSIX) timestamps\n",
    "    detail_data_clean_df.loc[:,\"B_DATE_TIME\"] = pd.to_datetime(detail_data_clean_df.loc[:,\"BEGIN_DATE_TIME\"],\n",
    "                                                               format=\"%d-%b-%Y %H:%M:%S\")\n",
    "    detail_data_clean_df.loc[:,\"E_DATE_TIME\"] = pd.to_datetime(detail_data_clean_df.loc[:,\"END_DATE_TIME\"],\n",
    "                                                               format=\"%d-%b-%Y %H:%M:%S\")\n",
    "    \n",
    "    detail_data_clean_df = detail_data_clean_df.merge(timezones_df, on=\"CZ_TIMEZONE\", how=\"left\")\n",
    "\n",
    "    detail_data_clean_df[\"B_DATE_TIME\"] = detail_data_clean_df[\"B_DATE_TIME\"]\\\n",
    "                                        - pd.TimedeltaIndex(detail_data_clean_df[\"UTC_OFFSET\"], unit=\"H\")\n",
    "    detail_data_clean_df[\"E_DATE_TIME\"] = detail_data_clean_df[\"E_DATE_TIME\"]\\\n",
    "                                        - pd.TimedeltaIndex(detail_data_clean_df[\"UTC_OFFSET\"], unit=\"H\")\n",
    "    \n",
    "    detail_data_clean_df.loc[:,\"BEGIN_TIMESTAMP\"] = detail_data_clean_df.loc[:,\"B_DATE_TIME\"].astype(\"int64\") // 10**9\n",
    "    detail_data_clean_df.loc[:,\"END_TIMESTAMP\"] = detail_data_clean_df.loc[:,\"E_DATE_TIME\"].astype(\"int64\") // 10**9\n",
    "\n",
    "    # Get F/EF scale codes\n",
    "    detail_data_clean_df[\"TOR_F_SCALE\"] = detail_data_clean_df[\"TOR_F_SCALE\"].fillna(\"EFU\")\n",
    "    pattern = r'F(\\w)'\n",
    "    detail_data_clean_df[\"TOR_F_LEVEL\"] = detail_data_clean_df[\"TOR_F_SCALE\"].str.extract(pattern)\n",
    "\n",
    "    # Accumulate Deaths & Injuries\n",
    "    detail_data_clean_df[\"DEATHS\"] = detail_data_clean_df[\"DEATHS_DIRECT\"] + detail_data_clean_df[\"DEATHS_INDIRECT\"]\n",
    "    detail_data_clean_df[\"INJURIES\"] = detail_data_clean_df[\"INJURIES_DIRECT\"] + detail_data_clean_df[\"INJURIES_INDIRECT\"]\n",
    "\n",
    "    #print(\"DAMAGE_PROPERTY RAW: \", detail_data_clean_df[\"DAMAGE_PROPERTY\"].value_counts())\n",
    "\n",
    "    # Convert DAMAGE_PROPERTY to numeric\n",
    "    detail_data_clean_df.loc[:,\"DAMAGE_PROPERTY\"] = detail_data_clean_df.loc[:,\"DAMAGE_PROPERTY\"].fillna(\"0.00K\")\n",
    "    detail_data_clean_df.loc[detail_data_clean_df[\"DAMAGE_PROPERTY\"].str.match(r'\\d*[.]?\\d*[^KMB]\\Z'), \"DAMAGE_PROPERTY\"] += \"K\"\n",
    "\n",
    "    pattern = r'(\\d*[.]?\\d*)[KMB]'\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].str.extract(pattern).astype(float)\n",
    "    pattern = r'\\d*[.]?\\d*([KMB])'\n",
    "    detail_data_clean_df[\"DMG_PRP_MULT_STR\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].str.extract(pattern)\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = (detail_data_clean_df[\"DMG_PRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_PRP_MULT_STR\"] == \"K\", 1000, 1))\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = (detail_data_clean_df[\"DMG_PRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_PRP_MULT_STR\"] == \"M\", 1000000, 1))\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = (detail_data_clean_df[\"DMG_PRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_PRP_MULT_STR\"] == \"B\", 1000000000, 1))\n",
    "\n",
    "    # Convert DAMAGE_CROPS to numeric\n",
    "    detail_data_clean_df.loc[:,\"DAMAGE_CROPS\"] = detail_data_clean_df.loc[:,\"DAMAGE_CROPS\"].fillna(\"0.00K\")\n",
    "    detail_data_clean_df.loc[detail_data_clean_df[\"DAMAGE_CROPS\"].str.match(r'\\d*[.]?\\d*[^KMB]\\Z'), \"DAMAGE_CROPS\"] += \"K\"\n",
    "\n",
    "    pattern = r'(\\d*[.]?\\d*)[KMB]'\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].str.extract(pattern).astype(float)\n",
    "    pattern = r'\\d*[.]?\\d*([KMB])'\n",
    "    detail_data_clean_df[\"DMG_CRP_MULT_STR\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].str.extract(pattern)\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = (detail_data_clean_df[\"DMG_CRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_CRP_MULT_STR\"] == \"K\", 1000, 1))\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = (detail_data_clean_df[\"DMG_CRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_CRP_MULT_STR\"] == \"M\", 1000000, 1))\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = (detail_data_clean_df[\"DMG_CRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_CRP_MULT_STR\"] == \"B\", 1000000000, 1))\n",
    "    \n",
    "    # Trim columns\n",
    "    detail_data_clean_df = detail_data_clean_df[[\n",
    "       'EVENT_ID', 'FIPS',\n",
    "       'BEGIN_TIMESTAMP', 'END_TIMESTAMP',\n",
    "       'DEATHS', 'INJURIES', 'DMG_PRP', 'DMG_CRP',\n",
    "       'TOR_F_SCALE', 'TOR_F_LEVEL', 'TOR_LENGTH', 'TOR_WIDTH',        \n",
    "       'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION',\n",
    "       'END_RANGE', 'END_AZIMUTH', 'END_LOCATION',\n",
    "       'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
    "       'EVENT_NARRATIVE']]\n",
    "    \n",
    "    # Rename temporary columns back to their original names\n",
    "    detail_data_clean_df = detail_data_clean_df.rename({\"DMG_PRP\": \"DAMAGE_PROPERTY\",\n",
    "                                                        \"DMG_CRP\": \"DAMAGE_CROPS\" }, axis=1)\n",
    "\n",
    "    # Fix numeric dtypes\n",
    "    detail_data_clean_df[\"DAMAGE_PROPERTY\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].astype(\"int64\")\n",
    "    detail_data_clean_df[\"DAMAGE_CROPS\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].astype(\"int64\")\n",
    "\n",
    "    return detail_data_clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1950_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1951_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1952_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1953_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1954_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1955_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1956_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1957_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1958_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1959_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1960_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1961_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1962_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1963_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1964_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1965_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1966_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1967_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1968_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1969_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1970_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1971_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1972_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1973_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1974_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1975_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1976_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1977_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1978_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1979_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1980_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1981_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1982_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1983_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1984_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1985_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1986_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1987_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1988_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1989_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1990_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1991_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1992_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1993_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1994_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1995_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1996_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1997_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1998_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1999_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2000_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2001_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2002_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2003_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2004_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2005_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2006_c20250122.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2007_c20240216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2008_c20240620.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2009_c20231116.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2010_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2011_c20230417.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2012_c20221216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2013_c20230118.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2014_c20231116.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2015_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2016_c20220719.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2017_c20250122.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2018_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2019_c20240117.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2020_c20240620.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2021_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2022_c20241121.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2023_c20241216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2024_c20250122.csv\n",
      "File processing complete\n",
      "File written to ../Data/Cleaned//Tornadoes_1950_2024.csv\n",
      "File written to ../Data/Cleaned//Tornadoes_1950_2024.json\n"
     ]
    }
   ],
   "source": [
    "enabled = True\n",
    "write = True\n",
    "\n",
    "if enabled:\n",
    "    df_list = [process_file(file) for file in files]\n",
    "    details_full_df = pd.concat(df_list)\n",
    "    details_full_df = details_full_df.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    details_full_df = details_full_df.reset_index()\n",
    "    details_full_df = details_full_df.drop(columns=[\"index\"])\n",
    "    print(\"File processing complete\")\n",
    "\n",
    "    if write:\n",
    "        details_full_df.to_csv(f\"{output_path}/Tornadoes_1950_2024.csv\", index=False)\n",
    "        details_full_df.to_json(f\"{output_path}/Tornadoes_1950_2024.json\", orient='index')\n",
    "        print(f\"File written to {output_path}/Tornadoes_1950_2024.csv\")\n",
    "        print(f\"File written to {output_path}/Tornadoes_1950_2024.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      NaN\n",
       "1                                                      NaN\n",
       "2                                                      NaN\n",
       "3                                                      NaN\n",
       "4                                                      NaN\n",
       "                               ...                        \n",
       "78491    This tornado developed west of the S 560 Road ...\n",
       "78492    An EF-0 tornado formed shortly before 11pm CDT...\n",
       "78493    An EF-0 tornado formed at 1130pm CDT just east...\n",
       "78494    This tornado developed north of Highway 62 ove...\n",
       "78495    At the Oregon State University Ship Operations...\n",
       "Name: EVENT_NARRATIVE, Length: 78496, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df[\"EVENT_NARRATIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_fips = ['02101', '02155', '02181', '06000', '12000', '13597', '15000',\n",
    "            '16000', '29677', '30000', '32000', '37000', '40012', '40018', '40020',\n",
    "            '40026', '40028', '40030', '40032', '40038', '40040', '40046', '40048',\n",
    "            '40050', '40052', '46000', '46001', '46131', '51039', '51123', '51780',\n",
    "            '53000', '96010', '99003', '99005', '99008', '99009', '99010', '99011',\n",
    "            '99013', '99021', '99069', '99079', '99081', '99085', '99091', '99097',\n",
    "            '99099', '99127', '99139']\n",
    "\n",
    "#details_full_df[details_full_df[\"FIPS\"].isin(bad_fips)].to_csv(\"../Data/Cleaned/DEBUGGING.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>BEGIN_TIMESTAMP</th>\n",
       "      <th>END_TIMESTAMP</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>TOR_F_LEVEL</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_AZIMUTH</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EVENT_ID, FIPS, BEGIN_TIMESTAMP, END_TIMESTAMP, DEATHS, INJURIES, DAMAGE_PROPERTY, DAMAGE_CROPS, TOR_F_SCALE, TOR_F_LEVEL, TOR_LENGTH, TOR_WIDTH, BEGIN_RANGE, BEGIN_AZIMUTH, BEGIN_LOCATION, END_RANGE, END_AZIMUTH, END_LOCATION, BEGIN_LAT, BEGIN_LON, END_LAT, END_LON, EVENT_NARRATIVE]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_path = \"../../../Data/fips_data.csv\"\n",
    "fips_df = pd.read_csv(fips_path, dtype=str)\n",
    "fips_list = fips_df[\"FIPS\"].tolist()\n",
    "\n",
    "details_full_df[~details_full_df[\"FIPS\"].isin(fips_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CZ_NAME</th>\n",
       "      <th>BEGIN_TIMESTAMP</th>\n",
       "      <th>END_TIMESTAMP</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_AZIMUTH</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>10017020</td>\n",
       "      <td>19075</td>\n",
       "      <td>02-JUN-1952 18:30:00</td>\n",
       "      <td>IOWA</td>\n",
       "      <td>GRUNDY</td>\n",
       "      <td>-554772600</td>\n",
       "      <td>-554772600</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>9979090</td>\n",
       "      <td>01047</td>\n",
       "      <td>04-NOV-1959 15:20:00</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>DALLAS</td>\n",
       "      <td>-320553600</td>\n",
       "      <td>-320553600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34759</th>\n",
       "      <td>10317175</td>\n",
       "      <td>06007</td>\n",
       "      <td>07-JAN-1993 15:00:00</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>BUTTE</td>\n",
       "      <td>726447600</td>\n",
       "      <td>726447600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A barn roof was tossed 75 feet and 2 vehicles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34760</th>\n",
       "      <td>10320946</td>\n",
       "      <td>13309</td>\n",
       "      <td>08-JAN-1993 04:00:00</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>WHEELER</td>\n",
       "      <td>726483600</td>\n",
       "      <td>726483600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alamo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A small tornado developed at Alamo and moved e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34762</th>\n",
       "      <td>10319606</td>\n",
       "      <td>12057</td>\n",
       "      <td>08-JAN-1993 14:00:00</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>HILLSBOROUGH</td>\n",
       "      <td>726519600</td>\n",
       "      <td>726519600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A small tornado touched down briefly blowing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73264</th>\n",
       "      <td>986081</td>\n",
       "      <td>39153</td>\n",
       "      <td>21-OCT-2021 16:08:00</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>SUMMIT</td>\n",
       "      <td>1634850480</td>\n",
       "      <td>1634850660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A brief EF0 tornado with estimated maximum win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73265</th>\n",
       "      <td>986070</td>\n",
       "      <td>39151</td>\n",
       "      <td>21-OCT-2021 16:10:00</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>STARK</td>\n",
       "      <td>1634850600</td>\n",
       "      <td>1634850900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An EF1 tornado with estimated maximum winds of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73266</th>\n",
       "      <td>986136</td>\n",
       "      <td>39133</td>\n",
       "      <td>21-OCT-2021 16:21:00</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>PORTAGE</td>\n",
       "      <td>1634851260</td>\n",
       "      <td>1634851320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A very brief EF0 tornado with estimated maximu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73267</th>\n",
       "      <td>986122</td>\n",
       "      <td>39155</td>\n",
       "      <td>21-OCT-2021 17:15:00</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>TRUMBULL</td>\n",
       "      <td>1634854500</td>\n",
       "      <td>1634854620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A brief EF1 tornado with estimated maximum win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73268</th>\n",
       "      <td>986126</td>\n",
       "      <td>39155</td>\n",
       "      <td>21-OCT-2021 17:20:00</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>TRUMBULL</td>\n",
       "      <td>1634854800</td>\n",
       "      <td>1634854860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A very brief EF0 tornado with estimated maximu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EVENT_ID   FIPS       BEGIN_DATE_TIME       STATE       CZ_NAME  \\\n",
       "665    10017020  19075  02-JUN-1952 18:30:00        IOWA        GRUNDY   \n",
       "5227    9979090  01047  04-NOV-1959 15:20:00     ALABAMA        DALLAS   \n",
       "34759  10317175  06007  07-JAN-1993 15:00:00  CALIFORNIA         BUTTE   \n",
       "34760  10320946  13309  08-JAN-1993 04:00:00     GEORGIA       WHEELER   \n",
       "34762  10319606  12057  08-JAN-1993 14:00:00     FLORIDA  HILLSBOROUGH   \n",
       "...         ...    ...                   ...         ...           ...   \n",
       "73264    986081  39153  21-OCT-2021 16:08:00        OHIO        SUMMIT   \n",
       "73265    986070  39151  21-OCT-2021 16:10:00        OHIO         STARK   \n",
       "73266    986136  39133  21-OCT-2021 16:21:00        OHIO       PORTAGE   \n",
       "73267    986122  39155  21-OCT-2021 17:15:00        OHIO      TRUMBULL   \n",
       "73268    986126  39155  21-OCT-2021 17:20:00        OHIO      TRUMBULL   \n",
       "\n",
       "       BEGIN_TIMESTAMP  END_TIMESTAMP  DEATHS  INJURIES  DAMAGE_PROPERTY  ...  \\\n",
       "665         -554772600     -554772600       1         2                0  ...   \n",
       "5227        -320553600     -320553600       0         0                0  ...   \n",
       "34759        726447600      726447600       0         0                0  ...   \n",
       "34760        726483600      726483600       0         0                0  ...   \n",
       "34762        726519600      726519600       0         0                0  ...   \n",
       "...                ...            ...     ...       ...              ...  ...   \n",
       "73264       1634850480     1634850660       0         0                0  ...   \n",
       "73265       1634850600     1634850900       0         0                0  ...   \n",
       "73266       1634851260     1634851320       0         0                0  ...   \n",
       "73267       1634854500     1634854620       0         0                0  ...   \n",
       "73268       1634854800     1634854860       0         0                0  ...   \n",
       "\n",
       "       BEGIN_AZIMUTH BEGIN_LOCATION END_RANGE  END_AZIMUTH  END_LOCATION  \\\n",
       "665              NaN            NaN       0.0          NaN           NaN   \n",
       "5227             NaN            NaN       0.0          NaN           NaN   \n",
       "34759            NaN          Biggs       0.0          NaN           NaN   \n",
       "34760            NaN          Alamo       0.0          NaN           NaN   \n",
       "34762            NaN            NaN       0.0          NaN           NaN   \n",
       "...              ...            ...       ...          ...           ...   \n",
       "73264            NaN            NaN       NaN          NaN           NaN   \n",
       "73265            NaN            NaN       NaN          NaN           NaN   \n",
       "73266            NaN            NaN       NaN          NaN           NaN   \n",
       "73267            NaN            NaN       NaN          NaN           NaN   \n",
       "73268            NaN            NaN       NaN          NaN           NaN   \n",
       "\n",
       "       BEGIN_LAT BEGIN_LON END_LAT  END_LON  \\\n",
       "665          NaN       NaN     NaN      NaN   \n",
       "5227         NaN       NaN     NaN      NaN   \n",
       "34759        NaN       NaN     NaN      NaN   \n",
       "34760        NaN       NaN     NaN      NaN   \n",
       "34762        NaN       NaN     NaN      NaN   \n",
       "...          ...       ...     ...      ...   \n",
       "73264        NaN       NaN     NaN      NaN   \n",
       "73265        NaN       NaN     NaN      NaN   \n",
       "73266        NaN       NaN     NaN      NaN   \n",
       "73267        NaN       NaN     NaN      NaN   \n",
       "73268        NaN       NaN     NaN      NaN   \n",
       "\n",
       "                                         EVENT_NARRATIVE  \n",
       "665                                                  NaN  \n",
       "5227                                                 NaN  \n",
       "34759  A barn roof was tossed 75 feet and 2 vehicles ...  \n",
       "34760  A small tornado developed at Alamo and moved e...  \n",
       "34762  A small tornado touched down briefly blowing a...  \n",
       "...                                                  ...  \n",
       "73264  A brief EF0 tornado with estimated maximum win...  \n",
       "73265  An EF1 tornado with estimated maximum winds of...  \n",
       "73266  A very brief EF0 tornado with estimated maximu...  \n",
       "73267  A brief EF1 tornado with estimated maximum win...  \n",
       "73268  A very brief EF0 tornado with estimated maximu...  \n",
       "\n",
       "[1200 rows x 26 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df[details_full_df['BEGIN_LAT'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_tornado_segment(df, current_index):\n",
    "    #print(\"____________FIND NEXT SEGMENT____________\")\n",
    "\n",
    "    iterrable_df = pd.DataFrame(df).copy()\n",
    "    \n",
    "    current_df = iterrable_df.iloc[current_index:,:]\n",
    "    current_row = current_df.iloc[0:1,:]\n",
    "\n",
    "    next_fips = current_row.loc[:,\"TOR_OTHER_CZ_FIPS\"].values[0]\n",
    "    next_wfo = current_row.loc[:,\"TOR_OTHER_WFO\"].values[0]\n",
    "    next_timestamp = current_row.loc[:,\"END_TIMESTAMP\"].values[0]    \n",
    "\n",
    "    found = iterrable_df[(iterrable_df[\"CZ_FIPS\"] == next_fips) &\n",
    "                          (iterrable_df[\"WFO\"] == next_wfo) &\n",
    "                          (iterrable_df[\"BEGIN_TIMESTAMP\"] == next_timestamp)]\n",
    "\n",
    "    if (len(found) == 0):\n",
    "        print(f\"\"\"    Next FIPS: {next_fips}\n",
    "    Next WFO: {next_wfo}\n",
    "    Next Timestamp: {next_timestamp}\"\"\")\n",
    "        print(\"Next segment not found.\")\n",
    "        return -1        \n",
    "    else:\n",
    "        return found.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_segments(df):\n",
    "    print(\"____________IDENTIFY SEGMENTS____________\")\n",
    "    segments_df = df.copy()\n",
    "    segments_df = segments_df[segments_df[\"TOR_OTHER_CZ_FIPS\"].notna()]\n",
    "    return segments_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tornadoes(df, tornado_id):\n",
    "    print(\"____________IDENTIFY TORNADOES____________\")\n",
    "    #segment_indices = identify_segments(df)\n",
    "    # print(segment_indices)\n",
    "\n",
    "    #global tornado_id\n",
    "    work_df = pd.DataFrame(df).copy()\n",
    "    #global detail_data_clean_pd\n",
    "\n",
    "    for index, row in work_df.iterrows():\n",
    "        if row[\"TORNADO_ID\"] == 0:\n",
    "            this_row = work_df.iloc[index:index+1,:]\n",
    "            #work_df.loc[index:index+1,\"TORNADO_ID\"] = tornado_id\n",
    "            #this_row = work_df.loc[index,:]\n",
    "            work_df.loc[index,\"TORNADO_ID\"] = tornado_id\n",
    "            is_segment = this_row[\"TOR_OTHER_CZ_FIPS\"].notna()\n",
    "            if is_segment.values[0]:\n",
    "                #print(f\"EVENT_ID: {this_row[\"EVENT_ID\"].values[0]} TOR_OTHER_CZ_FIPS: {this_row[\"TOR_OTHER_CZ_FIPS\"].values[0]}\")\n",
    "                #print(f\"Index: {index}\")\n",
    "                next_segment_index = find_next_tornado_segment(work_df, index)\n",
    "                if (next_segment_index > -1):\n",
    "                    work_df.loc[next_segment_index,\"TORNADO_ID\"] = tornado_id\n",
    "                    print(f\"Next segment Tornado ID: {work_df.loc[next_segment_index,\"TORNADO_ID\"]}\")\n",
    "                #print(f\"   Next Segment Index: {next_segment_index}\")\n",
    "                #print(f\"Next: {find_next_tornado_segment(index)}\")\n",
    "            \n",
    "            tornado_id = tornado_id + 1\n",
    "\n",
    "    #tornado_id = tornado_id_temp\n",
    "    #print(tornado_id)\n",
    "    return work_df, tornado_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1993_c20220425.csv\n",
      "Empty DataFrame\n",
      "Columns: [BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, END_TIME, EPISODE_ID, EVENT_ID, STATE, STATE_FIPS, YEAR, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_FIPS, CZ_NAME, WFO, BEGIN_DATE_TIME, CZ_TIMEZONE, END_DATE_TIME, INJURIES_DIRECT, INJURIES_INDIRECT, DEATHS_DIRECT, DEATHS_INDIRECT, DAMAGE_PROPERTY, DAMAGE_CROPS, SOURCE, MAGNITUDE, MAGNITUDE_TYPE, FLOOD_CAUSE, CATEGORY, TOR_F_SCALE, TOR_LENGTH, TOR_WIDTH, TOR_OTHER_WFO, TOR_OTHER_CZ_STATE, TOR_OTHER_CZ_FIPS, TOR_OTHER_CZ_NAME, BEGIN_RANGE, BEGIN_AZIMUTH, BEGIN_LOCATION, END_RANGE, END_AZIMUTH, END_LOCATION, BEGIN_LAT, BEGIN_LON, END_LAT, END_LON, EPISODE_NARRATIVE, EVENT_NARRATIVE, DATA_SOURCE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n",
      "DAMAGE_PROPERTY RAW:  DAMAGE_PROPERTY\n",
      "0       226\n",
      "500K    116\n",
      "50K     105\n",
      "5K       76\n",
      "5M       51\n",
      ".5K      25\n",
      "50M       9\n",
      ".05K      4\n",
      "3         1\n",
      "30        1\n",
      "06        1\n",
      "1K        1\n",
      "Name: count, dtype: int64\n",
      "DAMAGE_PROPERTY CLEAN:  DAMAGE_PROPERTY\n",
      "0.0K    226\n",
      "500K    116\n",
      "50K     105\n",
      "5K       76\n",
      "5M       51\n",
      ".5K      25\n",
      "50M       9\n",
      ".05K      4\n",
      "3K        1\n",
      "30K       1\n",
      "06K       1\n",
      "1K        1\n",
      "Name: count, dtype: int64\n",
      "DMG_PRP_MULT_STR:  DMG_PRP_MULT_STR\n",
      "K    556\n",
      "M     60\n",
      "Name: count, dtype: int64\n",
      "DMG_PRP:  DMG_PRP\n",
      "0.0           226\n",
      "500000.0      116\n",
      "50000.0       105\n",
      "5000.0         76\n",
      "5000000.0      51\n",
      "500.0          25\n",
      "50000000.0      9\n",
      "50.0            4\n",
      "3000.0          1\n",
      "30000.0         1\n",
      "6000.0          1\n",
      "1000.0          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "enabled = True\n",
    "\n",
    "if enabled:\n",
    "    result = process_file(files[43])\n",
    "    result = result.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    \n",
    "    #print(\"DAMAGE_PROPERTY: \", result[\"DAMAGE_PROPERTY\"].unique())\n",
    "    #print(\"DAMAGE_CROPS: \", result[\"DAMAGE_CROPS\"].unique())\n",
    "    #print(result[\"FIPS\"])\n",
    "    #print(result[\"TOR_OTHER_FIPS\"].unique())\n",
    "    #print(result.columns)\n",
    "\n",
    "    #print(result.dtypes)\n",
    "    #result2, TEMP = identify_tornadoes(result, tornado_id)\n",
    "    #print(result2)\n",
    "    #print(f\"Unique tornado count: {len(result2[\"TORNADO_ID\"].unique())}\")\n",
    "    #print(result2[\"TORNADO_ID\"])\n",
    "    #result2.to_csv(\"tornado_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "\n",
    "if enabled:\n",
    "    result = process_file(files[-1])\n",
    "    result = result.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    #print(result.dtypes)\n",
    "    result2, TEMP = identify_tornadoes(result, tornado_id)\n",
    "    print(result2)\n",
    "    print(f\"Unique tornado count: {len(result2[\"TORNADO_ID\"].unique())}\")\n",
    "    print(result2[\"TORNADO_ID\"])\n",
    "    result2.to_csv(\"tornado_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>WFO</th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>BEGIN_TIMESTAMP</th>\n",
       "      <th>END_TIMESTAMP</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>TORNADO_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>10033097</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GMT-0</td>\n",
       "      <td>-57084720</td>\n",
       "      <td>-57084720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.3</td>\n",
       "      <td>-92.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EVENT_ID  CZ_FIPS  WFO CZ_TIMEZONE  BEGIN_TIMESTAMP  END_TIMESTAMP  \\\n",
       "452  10033097       49  NaN       GMT-0        -57084720      -57084720   \n",
       "\n",
       "     DEATHS  INJURIES  DAMAGE_PROPERTY  DAMAGE_CROPS  ... BEGIN_LOCATION  \\\n",
       "452       0         0                0             0  ...            NaN   \n",
       "\n",
       "     END_RANGE  END_AZIMUTH  END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT  \\\n",
       "452        0.0          NaN           NaN      32.3     -92.75     NaN   \n",
       "\n",
       "    END_LON  EVENT_NARRATIVE TORNADO_ID  \n",
       "452     NaN              NaN          0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#details_full_df[details_full_df[\"CZ_TIMEZONE\"] == \"GMT-0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CZ_TIMEZONE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Apps\\Python\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CZ_TIMEZONE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m details_full_df[details_full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCZ_TIMEZONE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mf:\\Apps\\Python\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Apps\\Python\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CZ_TIMEZONE'"
     ]
    }
   ],
   "source": [
    "#details_full_df[details_full_df[\"CZ_TIMEZONE\"] == \"UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVENT_ID               int64\n",
       "CZ_FIPS                Int64\n",
       "WFO                   object\n",
       "CZ_TIMEZONE           object\n",
       "BEGIN_TIMESTAMP        int64\n",
       "END_TIMESTAMP          int64\n",
       "DEATHS                 int64\n",
       "INJURIES               int64\n",
       "DAMAGE_PROPERTY        int64\n",
       "DAMAGE_CROPS           int64\n",
       "TOR_F_SCALE           object\n",
       "TOR_LENGTH           float64\n",
       "TOR_WIDTH            float64\n",
       "TOR_OTHER_CZ_FIPS      Int64\n",
       "TOR_OTHER_WFO         object\n",
       "BEGIN_RANGE          float64\n",
       "BEGIN_AZIMUTH         object\n",
       "BEGIN_LOCATION        object\n",
       "END_RANGE            float64\n",
       "END_AZIMUTH           object\n",
       "END_LOCATION          object\n",
       "BEGIN_LAT            float64\n",
       "BEGIN_LON            float64\n",
       "END_LAT              float64\n",
       "END_LON              float64\n",
       "EVENT_NARRATIVE       object\n",
       "TORNADO_ID             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78496\n",
      "78496\n"
     ]
    }
   ],
   "source": [
    "print(len(details_full_df[\"EVENT_ID\"].unique()))\n",
    "print(len(details_full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd = detail_data_clean_pd.drop(columns=[\"MONTH_NAME\",  \"SOURCE\",\n",
    "#                                                          \"MAGNITUDE\", \"MAGNITUDE_TYPE\", \"FLOOD_CAUSE\", \"CATEGORY\",\n",
    "#                                                          \"DATA_SOURCE\"])\n",
    "#detail_data_clean_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_YEARMONTH\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].astype(str)\n",
    "#detail_data_clean_pd[\"BEGIN_YEARMONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"(\\d{4})\"\n",
    "#detail_data_clean_pd[\"BEGIN_YEAR\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"BEGIN_YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"\\d{4}(\\d{2})\"\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"END_YEARMONTH\"] = detail_data_clean_pd[\"END_YEARMONTH\"].astype(str)\n",
    "#detail_data_clean_pd[\"END_YEARMONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"(\\d{4})\"\n",
    "#detail_data_clean_pd[\"END_YEAR\"] = detail_data_clean_pd[\"END_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"END_YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"\\d{4}(\\d{2})\"\n",
    "#detail_data_clean_pd[\"END_MONTH\"] = detail_data_clean_pd[\"END_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"END_MONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_YEAR\"] = detail_data_clean_pd[\"BEGIN_YEAR\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"] = detail_data_clean_pd[\"BEGIN_MONTH\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"END_YEAR\"] = detail_data_clean_pd[\"END_YEAR\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"END_MONTH\"] = detail_data_clean_pd[\"END_MONTH\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd = detail_data_clean_pd.drop(columns=[\"BEGIN_YEARMONTH\", \"END_YEARMONTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_LOC\"] = detail_data_clean_pd['BEGIN_RANGE'].astype(str) + \" miles \" + detail_data_clean_pd['BEGIN_AZIMUTH'] + \" of \" + detail_data_clean_pd['BEGIN_LOCATION'] + \", \" + detail_data_clean_pd['STATE']\n",
    "#detail_data_clean_pd[\"BEGIN_LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"END_LOC\"] = detail_data_clean_pd['END_RANGE'].astype(str) + \" miles \" + detail_data_clean_pd['BEGIN_AZIMUTH'] + \" of \" + detail_data_clean_pd['END_LOCATION'] + \", \" + detail_data_clean_pd['STATE']\n",
    "#detail_data_clean_pd[\"END_LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
