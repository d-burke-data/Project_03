{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files in the Details folder\n",
    "details_path = \"../Data/Details/\"\n",
    "files = [f\"{details_path}{filename}\" for filename in os.listdir(details_path) if os.path.isfile((os.path.join(details_path, filename)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_OTHER_STATE_FIPS</th>\n",
       "      <th>TOR_OTHER_CZ_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TOR_OTHER_STATE_FIPS TOR_OTHER_CZ_STATE\n",
       "0                   01                 AL\n",
       "1                   02                 AK\n",
       "2                   04                 AZ\n",
       "3                   05                 AR\n",
       "4                   06                 CA"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get state FIPS for OTHER_FIPS conversion\n",
    "state_fips_path = \"../Data/cleaned_state.csv\"\n",
    "state_fips_df = pd.read_csv(state_fips_path, dtype=str)\n",
    "state_fips_df = state_fips_df.rename(columns={\"STATEFP\": \"TOR_OTHER_STATE_FIPS\", \"STATE\": \"TOR_OTHER_CZ_STATE\"})\n",
    "state_fips_df = state_fips_df.drop(columns=[\"Unnamed: 0\"])\n",
    "state_fips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../Data/Cleaned/\"\n",
    "tornado_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>CZ_TIMEZONE_RECODE</th>\n",
       "      <th>UTC_OFFSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CST</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MST</td>\n",
       "      <td>MST-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EST</td>\n",
       "      <td>EST-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PST</td>\n",
       "      <td>PST-8</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CDT</td>\n",
       "      <td>CDT-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDT</td>\n",
       "      <td>EDT-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MDT</td>\n",
       "      <td>MDT-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GMT</td>\n",
       "      <td>GMT-0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HST</td>\n",
       "      <td>HST-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PDT</td>\n",
       "      <td>PDT-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CSC</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AST</td>\n",
       "      <td>AST-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EST-5</td>\n",
       "      <td>EST-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MST-7</td>\n",
       "      <td>MST-7</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CST-6</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PST-8</td>\n",
       "      <td>PST-8</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AST-4</td>\n",
       "      <td>AST-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HST-10</td>\n",
       "      <td>HST-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AKST-9</td>\n",
       "      <td>AKST-9</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CZ_TIMEZONE CZ_TIMEZONE_RECODE  UTC_OFFSET\n",
       "0          CST              CST-6          -6\n",
       "1          MST              MST-7          -7\n",
       "2          EST              EST-5          -5\n",
       "3          PST              PST-8          -8\n",
       "4          UNK                UNK           0\n",
       "5          CDT              CDT-5          -5\n",
       "6          EDT              EDT-4          -4\n",
       "7          MDT              MDT-6          -6\n",
       "8          GMT              GMT-0           0\n",
       "9          HST             HST-10         -10\n",
       "10         PDT              PDT-7          -7\n",
       "11         CSC              CST-6          -6\n",
       "12         AST              AST-4          -4\n",
       "13       EST-5              EST-5          -5\n",
       "14       MST-7              MST-7          -7\n",
       "15       CST-6              CST-6          -6\n",
       "16       PST-8              PST-8          -8\n",
       "17       AST-4              AST-4          -4\n",
       "18      HST-10             HST-10         -10\n",
       "19      AKST-9             AKST-9          -9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timezone data\n",
    "tz_codes = ['CST', 'MST', 'EST', 'PST', 'UNK', 'CDT', 'EDT', 'MDT', 'GMT', 'HST', 'PDT', 'CSC',\n",
    " 'AST', 'EST-5', 'MST-7', 'CST-6', 'PST-8', 'AST-4', 'HST-10', 'AKST-9']\n",
    "tz_offsets = [-6, -7, -5, -8, 0, -5, -4, -6, 0, -10, -7, -6, -4, -5, -7, -6, -8, -4, -10, -9]\n",
    "tz_recode = ['CST-6', 'MST-7', 'EST-5', 'PST-8', 'UNK', 'CDT-5', 'EDT-4', 'MDT-6', 'GMT-0',\n",
    "             'HST-10', 'PDT-7', 'CST-6', 'AST-4', 'EST-5', 'MST-7', 'CST-6', 'PST-8', 'AST-4',\n",
    "             'HST-10', 'AKST-9']\n",
    "timezones_df = pd.DataFrame({\n",
    "    \"CZ_TIMEZONE\": tz_codes,\n",
    "    \"CZ_TIMEZONE_RECODE\": tz_recode,\n",
    "    \"UTC_OFFSET\": tz_offsets\n",
    "})\n",
    "\n",
    "timezones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    print(f\"Processing file {file}\")\n",
    "    # Read file\n",
    "    detail_data_raw_df = pd.read_csv(file)\n",
    "    \n",
    "    # Filter tornadoes\n",
    "    detail_data_clean_df = detail_data_raw_df[detail_data_raw_df[\"EVENT_TYPE\"] == \"Tornado\"]\n",
    "\n",
    "    # Combine State and County FIPS\n",
    "    detail_data_clean_df[\"FIPS\"] = (detail_data_clean_df[\"STATE_FIPS\"].astype(str).str.zfill(2)) + (detail_data_clean_df[\"CZ_FIPS\"].astype(str).str.zfill(3))\n",
    "    \n",
    "    #filter = detail_data_clean_df[\"TOR_OTHER_CZ_FIPS\"].notna()\n",
    "    #detail_data_clean_df[\"TOR_OTHER_CZ_STATE\"] = detail_data_clean_df[\"TOR_OTHER_CZ_STATE\"].astype(str)\n",
    "    #detail_data_clean_df = detail_data_clean_df.merge(state_fips_df, on=\"TOR_OTHER_CZ_STATE\", how=\"left\")\n",
    "    #detail_data_clean_df[\"TOR_OTHER_STATE_FIPS\"] = detail_data_clean_df[filter][\"TOR_OTHER_STATE_FIPS\"].astype(\"Int64\").astype(str).str.zfill(2).replace(\"<NA>\", \"\")\n",
    "    #detail_data_clean_df[\"TOR_OTHER_CZ_FIPS\"] = detail_data_clean_df[filter][\"TOR_OTHER_CZ_FIPS\"].astype(\"Int64\").astype(str).str.zfill(3).replace(\"<NA>\", \"\")\n",
    "    #detail_data_clean_df[\"TOR_OTHER_FIPS\"] = (detail_data_clean_df[\"TOR_OTHER_STATE_FIPS\"]) + (detail_data_clean_df[\"TOR_OTHER_CZ_FIPS\"])\n",
    "\n",
    "    # Process timestamps\n",
    "    pattern = r'-\\d{2}'\n",
    "    detail_data_clean_df[\"YEAR\"] = detail_data_clean_df[\"YEAR\"].astype(str)\n",
    " \n",
    "    # FROM MICROSOFT COPILOT\n",
    "    # Replace 2-digit year with 4-digit year for timestamp creation\n",
    "    detail_data_clean_df[\"BEGIN_DATE_TIME\"] = detail_data_clean_df.apply(\n",
    "        lambda row: pd.Series(row[\"BEGIN_DATE_TIME\"]).str.replace(pattern, f\"-{row[\"YEAR\"]}\", regex=True)[0],axis=1)\n",
    "    detail_data_clean_df[\"END_DATE_TIME\"] = detail_data_clean_df.apply(\n",
    "        lambda row: pd.Series(row[\"END_DATE_TIME\"]).str.replace(pattern, f\"-{row[\"YEAR\"]}\", regex=True)[0],axis=1)\n",
    "    \n",
    "    # Convert BEGIN_DATE_TIME and END_DATE_TIME to UTC UNIX (POSIX) timestamps\n",
    "    detail_data_clean_df.loc[:,\"B_DATE_TIME\"] = pd.to_datetime(detail_data_clean_df.loc[:,\"BEGIN_DATE_TIME\"],\n",
    "                                                               format=\"%d-%b-%Y %H:%M:%S\")\n",
    "    detail_data_clean_df.loc[:,\"E_DATE_TIME\"] = pd.to_datetime(detail_data_clean_df.loc[:,\"END_DATE_TIME\"],\n",
    "                                                               format=\"%d-%b-%Y %H:%M:%S\")\n",
    "    \n",
    "    detail_data_clean_df = detail_data_clean_df.merge(timezones_df, on=\"CZ_TIMEZONE\", how=\"left\")\n",
    "\n",
    "    detail_data_clean_df[\"B_DATE_TIME\"] = detail_data_clean_df[\"B_DATE_TIME\"]\\\n",
    "                                        - pd.TimedeltaIndex(detail_data_clean_df[\"UTC_OFFSET\"], unit=\"H\")\n",
    "    detail_data_clean_df[\"E_DATE_TIME\"] = detail_data_clean_df[\"E_DATE_TIME\"]\\\n",
    "                                        - pd.TimedeltaIndex(detail_data_clean_df[\"UTC_OFFSET\"], unit=\"H\")\n",
    "    \n",
    "    detail_data_clean_df.loc[:,\"BEGIN_TIMESTAMP\"] = detail_data_clean_df.loc[:,\"B_DATE_TIME\"].astype(\"int64\") // 10**9\n",
    "    detail_data_clean_df.loc[:,\"END_TIMESTAMP\"] = detail_data_clean_df.loc[:,\"E_DATE_TIME\"].astype(\"int64\") // 10**9\n",
    "\n",
    "    #detail_data_clean_df[\"UNTIMESTAMP\"] = pd.to_datetime(detail_data_clean_df[\"BEGIN_TIMESTAMP\"], unit='s')\n",
    "    #print(detail_data_clean_df[[\"BEGIN_DATE_TIME\", \"UNTIMESTAMP\", \"BEGIN_TIMESTAMP\"]])\n",
    "    #detail_data_clean_df[\"UNTIMESTAMP\"] = pd.to_datetime(detail_data_clean_df[\"END_TIMESTAMP\"], unit='s')\n",
    "    #print(detail_data_clean_df[[\"END_DATE_TIME\", \"UNTIMESTAMP\", \"END_TIMESTAMP\"]])\n",
    "\n",
    "    # Get F/EF scale codes\n",
    "    detail_data_clean_df[\"TOR_F_SCALE\"] = detail_data_clean_df[\"TOR_F_SCALE\"].fillna(\"EFU\")\n",
    "    pattern = r'F(\\w)'\n",
    "    detail_data_clean_df[\"TOR_F_LEVEL\"] = detail_data_clean_df[\"TOR_F_SCALE\"].str.extract(pattern)\n",
    "\n",
    "    # Accumulate Deaths & Injuries\n",
    "    detail_data_clean_df[\"DEATHS\"] = detail_data_clean_df[\"DEATHS_DIRECT\"] + detail_data_clean_df[\"DEATHS_INDIRECT\"]\n",
    "    detail_data_clean_df[\"INJURIES\"] = detail_data_clean_df[\"INJURIES_DIRECT\"] + detail_data_clean_df[\"INJURIES_INDIRECT\"]\n",
    "\n",
    "    # Convert DAMAGE_PROPERTY to numeric\n",
    "    detail_data_clean_df[\"DAMAGE_PROPERTY\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].astype(str)\n",
    "    detail_data_clean_df.loc[:,\"DAMAGE_PROPERTY\"] = detail_data_clean_df.loc[:,\"DAMAGE_PROPERTY\"].fillna(\"0.00K\")\n",
    "    detail_data_clean_df[\"DAMAGE_PROPERTY\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].where(detail_data_clean_df[\"DAMAGE_PROPERTY\"] == 0, \"0.00K\")\n",
    "\n",
    "    pattern = r'(\\d+[.]*\\d*)[KM]'\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].str.extract(pattern).astype(float)\n",
    "    pattern = r'\\d+[.]*\\d*([KM])'\n",
    "    detail_data_clean_df[\"DMG_PRP_MULT_STR\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].str.extract(pattern)\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = (detail_data_clean_df[\"DMG_PRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_PRP_MULT_STR\"] == \"K\", 1000, 1))\n",
    "    detail_data_clean_df[\"DMG_PRP\"] = (detail_data_clean_df[\"DMG_PRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_PRP_MULT_STR\"] == \"M\", 1000000, 1))\n",
    "    \n",
    "    # Convert DAMAGE_CROPS to numeric\n",
    "    detail_data_clean_df[\"DAMAGE_CROPS\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].astype(str)\n",
    "    detail_data_clean_df.loc[:,\"DAMAGE_CROPS\"] = detail_data_clean_df.loc[:,\"DAMAGE_CROPS\"].fillna(\"0.00K\")\n",
    "    detail_data_clean_df[\"DAMAGE_CROPS\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].where(detail_data_clean_df[\"DAMAGE_CROPS\"] == 0, \"0.00K\")\n",
    "\n",
    "    pattern = r'(\\d+[.]*\\d*)[KM]'\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].str.extract(pattern).astype(float)\n",
    "    pattern = r'\\d+[.]*\\d*([KM])'\n",
    "    detail_data_clean_df[\"DMG_CRP_MULT_STR\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].str.extract(pattern)\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = (detail_data_clean_df[\"DMG_CRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_CRP_MULT_STR\"] == \"K\", 1000, 1))\n",
    "    detail_data_clean_df[\"DMG_CRP\"] = (detail_data_clean_df[\"DMG_CRP\"] * \n",
    "                                        np.where(detail_data_clean_df[\"DMG_CRP_MULT_STR\"] == \"M\", 1000000, 1))\n",
    "\n",
    "    # Trim columns\n",
    "    detail_data_clean_df = detail_data_clean_df[[\n",
    "       'EVENT_ID', 'FIPS', 'WFO',\n",
    "       'CZ_TIMEZONE_RECODE', 'BEGIN_TIMESTAMP', 'END_TIMESTAMP',\n",
    "       'DEATHS', 'INJURIES', 'DMG_PRP', 'DMG_CRP',\n",
    "       'TOR_F_SCALE', 'TOR_F_LEVEL', 'TOR_LENGTH', 'TOR_WIDTH',\n",
    "        'TOR_OTHER_WFO',\n",
    "       'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION',\n",
    "       'END_RANGE', 'END_AZIMUTH', 'END_LOCATION',\n",
    "       'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
    "       'EVENT_NARRATIVE']]\n",
    "    \n",
    "    # Rename temporary columns back to their original names\n",
    "    detail_data_clean_df = detail_data_clean_df.rename({\"DMG_PRP\": \"DAMAGE_PROPERTY\",\n",
    "                                                        \"DMG_CRP\": \"DAMAGE_CROPS\",\n",
    "                                                        \"CZ_TIMEZONE_RECODE\": \"CZ_TIMEZONE\"}, axis=1)\n",
    "\n",
    "    # Fix numeric dtypes\n",
    "    #detail_data_clean_df[\"CZ_FIPS\"] = detail_data_clean_df[\"CZ_FIPS\"].astype(\"Int64\")\n",
    "    #detail_data_clean_df[\"TOR_OTHER_CZ_FIPS\"] = detail_data_clean_df[\"TOR_OTHER_CZ_FIPS\"].astype(\"Int64\")\n",
    "    detail_data_clean_df[\"DAMAGE_PROPERTY\"] = detail_data_clean_df[\"DAMAGE_PROPERTY\"].astype(\"int64\")\n",
    "    detail_data_clean_df[\"DAMAGE_CROPS\"] = detail_data_clean_df[\"DAMAGE_CROPS\"].astype(\"int64\")\n",
    "\n",
    "    detail_data_clean_df[\"TORNADO_ID\"] = 0\n",
    "\n",
    "    return detail_data_clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_tornado_segment(df, current_index):\n",
    "    #print(\"____________FIND NEXT SEGMENT____________\")\n",
    "\n",
    "    iterrable_df = pd.DataFrame(df).copy()\n",
    "    \n",
    "    current_df = iterrable_df.iloc[current_index:,:]\n",
    "    current_row = current_df.iloc[0:1,:]\n",
    "\n",
    "    next_fips = current_row.loc[:,\"TOR_OTHER_CZ_FIPS\"].values[0]\n",
    "    next_wfo = current_row.loc[:,\"TOR_OTHER_WFO\"].values[0]\n",
    "    next_timestamp = current_row.loc[:,\"END_TIMESTAMP\"].values[0]    \n",
    "\n",
    "    found = iterrable_df[(iterrable_df[\"CZ_FIPS\"] == next_fips) &\n",
    "                          (iterrable_df[\"WFO\"] == next_wfo) &\n",
    "                          (iterrable_df[\"BEGIN_TIMESTAMP\"] == next_timestamp)]\n",
    "\n",
    "    if (len(found) == 0):\n",
    "        print(f\"\"\"    Next FIPS: {next_fips}\n",
    "    Next WFO: {next_wfo}\n",
    "    Next Timestamp: {next_timestamp}\"\"\")\n",
    "        print(\"Next segment not found.\")\n",
    "        return -1        \n",
    "    else:\n",
    "        return found.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_segments(df):\n",
    "    print(\"____________IDENTIFY SEGMENTS____________\")\n",
    "    segments_df = df.copy()\n",
    "    segments_df = segments_df[segments_df[\"TOR_OTHER_CZ_FIPS\"].notna()]\n",
    "    return segments_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tornadoes(df, tornado_id):\n",
    "    print(\"____________IDENTIFY TORNADOES____________\")\n",
    "    #segment_indices = identify_segments(df)\n",
    "    # print(segment_indices)\n",
    "\n",
    "    #global tornado_id\n",
    "    work_df = pd.DataFrame(df).copy()\n",
    "    #global detail_data_clean_pd\n",
    "\n",
    "    for index, row in work_df.iterrows():\n",
    "        if row[\"TORNADO_ID\"] == 0:\n",
    "            this_row = work_df.iloc[index:index+1,:]\n",
    "            #work_df.loc[index:index+1,\"TORNADO_ID\"] = tornado_id\n",
    "            #this_row = work_df.loc[index,:]\n",
    "            work_df.loc[index,\"TORNADO_ID\"] = tornado_id\n",
    "            is_segment = this_row[\"TOR_OTHER_CZ_FIPS\"].notna()\n",
    "            if is_segment.values[0]:\n",
    "                #print(f\"EVENT_ID: {this_row[\"EVENT_ID\"].values[0]} TOR_OTHER_CZ_FIPS: {this_row[\"TOR_OTHER_CZ_FIPS\"].values[0]}\")\n",
    "                #print(f\"Index: {index}\")\n",
    "                next_segment_index = find_next_tornado_segment(work_df, index)\n",
    "                if (next_segment_index > -1):\n",
    "                    work_df.loc[next_segment_index,\"TORNADO_ID\"] = tornado_id\n",
    "                    print(f\"Next segment Tornado ID: {work_df.loc[next_segment_index,\"TORNADO_ID\"]}\")\n",
    "                #print(f\"   Next Segment Index: {next_segment_index}\")\n",
    "                #print(f\"Next: {find_next_tornado_segment(index)}\")\n",
    "            \n",
    "            tornado_id = tornado_id + 1\n",
    "\n",
    "    #tornado_id = tornado_id_temp\n",
    "    #print(tornado_id)\n",
    "    return work_df, tornado_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2024_c20250122.csv\n",
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
      "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
      "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
      "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
      "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
      "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
      "      dtype='object')\n",
      "27      48039\n",
      "19      12099\n",
      "24      12011\n",
      "145     22007\n",
      "379     28039\n",
      "        ...  \n",
      "1733    40115\n",
      "1696    29137\n",
      "1689    17001\n",
      "1723    05143\n",
      "1707    41041\n",
      "Name: FIPS, Length: 1901, dtype: object\n",
      "['' '12013' '12063' '01069' '13037' '37097' '13005' '17155' '55025'\n",
      " '55055' '17089' '39057' '39097' '39049' '39045' '39089' '12065' '13299'\n",
      " '17057' '17117' '21223' '21041' '18077' '18155' '39107' '39011' '39147'\n",
      " '39091' '39037' '39139' '39109' '39041' '05125' '28089' '40147' '29105'\n",
      " '17165' '18129' '18163' '18173' '21229' '21113' '21049' '39087' '54011'\n",
      " '18043' '21111' '21185' '01021' '51133' '19197' '22125' '28157' '28045'\n",
      " '20177' '19087' '19057' '19115' '29099' '17115' '40125' '40081' '40107'\n",
      " '31163' '48217' '31077' '31011' '31155' '31177' '20205' '20207' '19085'\n",
      " '19133' '31055' '19155' '31167' '19165' '19047' '19175' '19121' '19159'\n",
      " '19049' '29129' '40141' '40033' '29083' '40051' '40087' '40123' '40019'\n",
      " '48313' '20101' '31137' '31129' '40003' '40073' '20021' '40111' '29167'\n",
      " '29107' '29059' '05143' '29161' '29125' '05087' '17111' '55127' '26023'\n",
      " '18177' '39017' '54029' '42007' '37071' '17199' '29109' '47117' '01083'\n",
      " '29093' '29123' '01049' '01089' '47051' '13279' '01035' '01013' '12091'\n",
      " '12073' '12079' '54077' '37017' '42003' '40015' '19137' '19003' '19001'\n",
      " '19169' '55011' '55073' '40061' '48309' '48293' '48423' '48395' '31135'\n",
      " '31121' '31125' '31037' '19153' '19103' '19031' '19139' '19045' '17073'\n",
      " '48077' '48097' '48121' '40097' '05007' '05089' '29067' '05005' '05049'\n",
      " '05121' '29181' '29023' '29201' '29143' '21047' '21149' '29215' '29203'\n",
      " '17133' '17027' '17121' '29017' '17025' '21033' '21107' '17087' '18051'\n",
      " '17185' '21031' '21227' '21057' '21169' '21053' '48461' '28113' '01093'\n",
      " '24510' '27001' '17053' '55119' '55045' '55083' '31091' '31117' '42129'\n",
      " '25005' '18171' '31059' '22031' '22017' '48365' '48183' '22015' '48401'\n",
      " '48203' '48419' '05073' '22119' '05027' '17037' '17105' '17015' '17177'\n",
      " '17161' '17131' '17179' '17197' '17031' '18089' '18127' '18073' '36113'\n",
      " '18095' '39027' '27161' '45019' '45029' '39035' '39055' '37163' '37181'\n",
      " '51043' '27059' '27049' '55093' '45009' '45017' '45063' '12051' '12043'\n",
      " '12111' '12061' '12097' '12085']\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "enabled = False\n",
    "\n",
    "if enabled:\n",
    "    result = process_file(files[-1])\n",
    "    result = result.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    print(result[\"FIPS\"])\n",
    "    print(result[\"TOR_OTHER_FIPS\"].unique())\n",
    "    #print(result.columns)\n",
    "\n",
    "    #print(result.dtypes)\n",
    "    #result2, TEMP = identify_tornadoes(result, tornado_id)\n",
    "    #print(result2)\n",
    "    #print(f\"Unique tornado count: {len(result2[\"TORNADO_ID\"].unique())}\")\n",
    "    #print(result2[\"TORNADO_ID\"])\n",
    "    #result2.to_csv(\"tornado_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1950_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1951_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1952_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1953_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1954_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1955_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1956_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1957_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1958_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1959_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1960_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1961_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1962_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1963_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1964_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1965_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1966_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1967_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1968_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1969_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1970_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1971_c20210803.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1972_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1973_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1974_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1975_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1976_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1977_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1978_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1979_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1980_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1981_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1982_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1983_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1984_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1985_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1986_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1987_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1988_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1989_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1990_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1991_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1992_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1993_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1994_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1995_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1996_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1997_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1998_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d1999_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2000_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2001_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2002_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2003_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2004_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2005_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2006_c20250122.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2007_c20240216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2008_c20240620.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2009_c20231116.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2010_c20220425.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2011_c20230417.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2012_c20221216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2013_c20230118.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2014_c20231116.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2015_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2016_c20220719.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2017_c20250122.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2018_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2019_c20240117.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2020_c20240620.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2021_c20240716.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2022_c20241121.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2023_c20241216.csv\n",
      "Processing file ../Data/Details/StormEvents_details-ftp_v1.0_d2024_c20250122.csv\n",
      "File written to ../Data/Cleaned//Tornadoes_1950_2024.csv\n",
      "File written to ../Data/Cleaned//Tornadoes_1950_2024.json\n"
     ]
    }
   ],
   "source": [
    "enabled = True\n",
    "write = True\n",
    "\n",
    "if enabled:\n",
    "    df_list = [process_file(file) for file in files]\n",
    "    details_full_df = pd.concat(df_list)\n",
    "    details_full_df = details_full_df.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    details_full_df = details_full_df.reset_index()\n",
    "\n",
    "    if write:\n",
    "        details_full_df.to_csv(f\"{output_path}/Tornadoes_1950_2024.csv\", index=False)\n",
    "        details_full_df.to_json(f\"{output_path}/Tornadoes_1950_2024.json\")\n",
    "        print(f\"File written to {output_path}/Tornadoes_1950_2024.csv\")\n",
    "        print(f\"File written to {output_path}/Tornadoes_1950_2024.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "\n",
    "if enabled:\n",
    "    result = process_file(files[-1])\n",
    "    result = result.sort_values(\"BEGIN_TIMESTAMP\")\n",
    "    #print(result.dtypes)\n",
    "    result2, TEMP = identify_tornadoes(result, tornado_id)\n",
    "    print(result2)\n",
    "    print(f\"Unique tornado count: {len(result2[\"TORNADO_ID\"].unique())}\")\n",
    "    print(result2[\"TORNADO_ID\"])\n",
    "    result2.to_csv(\"tornado_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>WFO</th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>BEGIN_TIMESTAMP</th>\n",
       "      <th>END_TIMESTAMP</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>TORNADO_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>10033097</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GMT-0</td>\n",
       "      <td>-57084720</td>\n",
       "      <td>-57084720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.3</td>\n",
       "      <td>-92.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EVENT_ID  CZ_FIPS  WFO CZ_TIMEZONE  BEGIN_TIMESTAMP  END_TIMESTAMP  \\\n",
       "452  10033097       49  NaN       GMT-0        -57084720      -57084720   \n",
       "\n",
       "     DEATHS  INJURIES  DAMAGE_PROPERTY  DAMAGE_CROPS  ... BEGIN_LOCATION  \\\n",
       "452       0         0                0             0  ...            NaN   \n",
       "\n",
       "     END_RANGE  END_AZIMUTH  END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT  \\\n",
       "452        0.0          NaN           NaN      32.3     -92.75     NaN   \n",
       "\n",
       "    END_LON  EVENT_NARRATIVE TORNADO_ID  \n",
       "452     NaN              NaN          0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df[details_full_df[\"CZ_TIMEZONE\"] == \"GMT-0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>WFO</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>BEGIN_TIMESTAMP</th>\n",
       "      <th>END_TIMESTAMP</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>TORNADO_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>10039215</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>1956</td>\n",
       "      <td>UNK</td>\n",
       "      <td>-428675220</td>\n",
       "      <td>-428675220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.10</td>\n",
       "      <td>-72.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10092690</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>1957</td>\n",
       "      <td>UNK</td>\n",
       "      <td>-402279300</td>\n",
       "      <td>-402279300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-97.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>10005135</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>1967</td>\n",
       "      <td>UNK</td>\n",
       "      <td>-85145220</td>\n",
       "      <td>-85145220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.62</td>\n",
       "      <td>-85.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>10132933</td>\n",
       "      <td>309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1972</td>\n",
       "      <td>UNK</td>\n",
       "      <td>74628480</td>\n",
       "      <td>74628480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.40</td>\n",
       "      <td>-97.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>9996768</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>1973</td>\n",
       "      <td>UNK</td>\n",
       "      <td>102448800</td>\n",
       "      <td>102448800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.88</td>\n",
       "      <td>-83.58</td>\n",
       "      <td>33.92</td>\n",
       "      <td>-83.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>10008054</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>1974</td>\n",
       "      <td>UNK</td>\n",
       "      <td>145638180</td>\n",
       "      <td>145638180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-88.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>10010636</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAWAII</td>\n",
       "      <td>1980</td>\n",
       "      <td>UNK</td>\n",
       "      <td>322392000</td>\n",
       "      <td>322392000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.70</td>\n",
       "      <td>-155.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10123870</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH DAKOTA</td>\n",
       "      <td>1980</td>\n",
       "      <td>UNK</td>\n",
       "      <td>328984200</td>\n",
       "      <td>328984200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.95</td>\n",
       "      <td>-102.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>10127967</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1982</td>\n",
       "      <td>UNK</td>\n",
       "      <td>389975100</td>\n",
       "      <td>389975100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-101.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EVENT_ID  CZ_FIPS  WFO          STATE  YEAR CZ_TIMEZONE  BEGIN_TIMESTAMP  \\\n",
       "217  10039215       13  NaN  MASSACHUSETTS  1956         UNK       -428675220   \n",
       "107  10092690       85  NaN       OKLAHOMA  1957         UNK       -402279300   \n",
       "451  10005135      139  NaN        INDIANA  1967         UNK        -85145220   \n",
       "568  10132933      309  NaN          TEXAS  1972         UNK         74628480   \n",
       "880   9996768      219  NaN        GEORGIA  1973         UNK        102448800   \n",
       "460  10008054       29  NaN       ILLINOIS  1974         UNK        145638180   \n",
       "847  10010636        1  NaN         HAWAII  1980         UNK        322392000   \n",
       "42   10123870      105  NaN   SOUTH DAKOTA  1980         UNK        328984200   \n",
       "895  10127967       11  NaN          TEXAS  1982         UNK        389975100   \n",
       "\n",
       "     END_TIMESTAMP  DEATHS  INJURIES  ...  BEGIN_LOCATION  END_RANGE  \\\n",
       "217     -428675220       0         0  ...             NaN        0.0   \n",
       "107     -402279300       0         0  ...             NaN        0.0   \n",
       "451      -85145220       0         0  ...             NaN        0.0   \n",
       "568       74628480       0         0  ...             NaN        0.0   \n",
       "880      102448800       0         0  ...             NaN        0.0   \n",
       "460      145638180       0         0  ...             NaN        0.0   \n",
       "847      322392000       0         0  ...             NaN        0.0   \n",
       "42       328984200       0         0  ...             NaN        0.0   \n",
       "895      389975100       0         0  ...             NaN        0.0   \n",
       "\n",
       "    END_AZIMUTH  END_LOCATION  BEGIN_LAT  BEGIN_LON END_LAT  END_LON  \\\n",
       "217         NaN           NaN      42.10     -72.70     NaN      NaN   \n",
       "107         NaN           NaN      33.93     -97.52     NaN      NaN   \n",
       "451         NaN           NaN      39.62     -85.45     NaN      NaN   \n",
       "568         NaN           NaN      31.40     -97.22     NaN      NaN   \n",
       "880         NaN           NaN      33.88     -83.58   33.92   -83.47   \n",
       "460         NaN           NaN      39.45     -88.15     NaN      NaN   \n",
       "847         NaN           NaN      19.70    -155.10     NaN      NaN   \n",
       "42          NaN           NaN      45.95    -102.32     NaN      NaN   \n",
       "895         NaN           NaN      34.08    -101.23     NaN      NaN   \n",
       "\n",
       "    EVENT_NARRATIVE TORNADO_ID  \n",
       "217             NaN          0  \n",
       "107             NaN          0  \n",
       "451             NaN          0  \n",
       "568             NaN          0  \n",
       "880             NaN          0  \n",
       "460             NaN          0  \n",
       "847             NaN          0  \n",
       "42              NaN          0  \n",
       "895             NaN          0  \n",
       "\n",
       "[9 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df[details_full_df[\"CZ_TIMEZONE\"] == \"UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_unk = details_full_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVENT_ID               int64\n",
       "CZ_FIPS                Int64\n",
       "WFO                   object\n",
       "CZ_TIMEZONE           object\n",
       "BEGIN_TIMESTAMP        int64\n",
       "END_TIMESTAMP          int64\n",
       "DEATHS                 int64\n",
       "INJURIES               int64\n",
       "DAMAGE_PROPERTY        int64\n",
       "DAMAGE_CROPS           int64\n",
       "TOR_F_SCALE           object\n",
       "TOR_LENGTH           float64\n",
       "TOR_WIDTH            float64\n",
       "TOR_OTHER_CZ_FIPS      Int64\n",
       "TOR_OTHER_WFO         object\n",
       "BEGIN_RANGE          float64\n",
       "BEGIN_AZIMUTH         object\n",
       "BEGIN_LOCATION        object\n",
       "END_RANGE            float64\n",
       "END_AZIMUTH           object\n",
       "END_LOCATION          object\n",
       "BEGIN_LAT            float64\n",
       "BEGIN_LON            float64\n",
       "END_LAT              float64\n",
       "END_LON              float64\n",
       "EVENT_NARRATIVE       object\n",
       "TORNADO_ID             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78496\n",
      "78496\n"
     ]
    }
   ],
   "source": [
    "print(len(details_full_df[\"EVENT_ID\"].unique()))\n",
    "print(len(details_full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd = detail_data_clean_pd.drop(columns=[\"MONTH_NAME\",  \"SOURCE\",\n",
    "#                                                          \"MAGNITUDE\", \"MAGNITUDE_TYPE\", \"FLOOD_CAUSE\", \"CATEGORY\",\n",
    "#                                                          \"DATA_SOURCE\"])\n",
    "#detail_data_clean_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_YEARMONTH\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].astype(str)\n",
    "#detail_data_clean_pd[\"BEGIN_YEARMONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"(\\d{4})\"\n",
    "#detail_data_clean_pd[\"BEGIN_YEAR\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"BEGIN_YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"\\d{4}(\\d{2})\"\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"] = detail_data_clean_pd[\"BEGIN_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"END_YEARMONTH\"] = detail_data_clean_pd[\"END_YEARMONTH\"].astype(str)\n",
    "#detail_data_clean_pd[\"END_YEARMONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"(\\d{4})\"\n",
    "#detail_data_clean_pd[\"END_YEAR\"] = detail_data_clean_pd[\"END_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"END_YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r\"\\d{4}(\\d{2})\"\n",
    "#detail_data_clean_pd[\"END_MONTH\"] = detail_data_clean_pd[\"END_YEARMONTH\"].str.extract(pattern)\n",
    "#detail_data_clean_pd[\"END_MONTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_YEAR\"] = detail_data_clean_pd[\"BEGIN_YEAR\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"BEGIN_MONTH\"] = detail_data_clean_pd[\"BEGIN_MONTH\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"END_YEAR\"] = detail_data_clean_pd[\"END_YEAR\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd[\"END_MONTH\"] = detail_data_clean_pd[\"END_MONTH\"].astype(\"Int64\")\n",
    "#detail_data_clean_pd = detail_data_clean_pd.drop(columns=[\"BEGIN_YEARMONTH\", \"END_YEARMONTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"BEGIN_LOC\"] = detail_data_clean_pd['BEGIN_RANGE'].astype(str) + \" miles \" + detail_data_clean_pd['BEGIN_AZIMUTH'] + \" of \" + detail_data_clean_pd['BEGIN_LOCATION'] + \", \" + detail_data_clean_pd['STATE']\n",
    "#detail_data_clean_pd[\"BEGIN_LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail_data_clean_pd[\"END_LOC\"] = detail_data_clean_pd['END_RANGE'].astype(str) + \" miles \" + detail_data_clean_pd['BEGIN_AZIMUTH'] + \" of \" + detail_data_clean_pd['END_LOCATION'] + \", \" + detail_data_clean_pd['STATE']\n",
    "#detail_data_clean_pd[\"END_LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
